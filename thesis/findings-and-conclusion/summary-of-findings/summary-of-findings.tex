\section{Summary of Findings} \label{sec:findings-and-conclusion-summary-of-findings}

Section \ref{sec:introduction-research-objective-scope-research-objective} stated two objectives for our research. The first objective was to validate the hypothesis by showing that neural networks trained using symbols perform significantly better than those trained without the presence of symbols. We started by developing several recurrent neural networks to perform arithmetic on images of noisy handwritten digits with the aid of symbols represented as one-hot vectors. Two methods of presenting the symbols to the networks were developed and tested. The first used a separate input channel alongside the noisy inputs. The other method trained the recurrent network to classify the incoming digits on the first time steps. The results obtained by these initial models confirmed our hypothesis, and therefore accomplished the first objective, by showing that regardless of the technique used to provide symbols, the models trained in the presence of symbols performed significantly better than those trained in the absence of symbols. We did not find much difference between the models trained with the explicit symbols and those trained by learning to classify the input.

The second objective was to explain the role of symbols. In Section \ref{sec:theory-approach}, we expanded the objective by stating that in order to explain why symbols improve the accuracy of trained models, we have to show that the presence of symbols allows the neural networks to discover a representation that captures an algorithm that performs arithmetic operations, just as with humans symbols allow learners to generalize to unseen concepts. Experiments 4 and 5 in Section \ref{sec:empirical-studies-explaining-the-role-of-symbols} showed that this is a difficult task for networks trained using one-hot vector symbols. We were however able to show that the networks trained with symbols were able to capture the carry forward process of addition. This led us to consider other representations for the symbols.

We theorized that a symbol must exhibit three characteristics in order to be able to guide a learner to a general solution. They must be able to represent quantity, ordinal relations and capture the operation being performed. By using temperature encoded symbols we were able to develop LSTM based recurrent neural networks that perform well on combinations of digits that were not seen during training. We therefore concluded that temperature encoded symbols are able to capture the three aspects needed by the symbols to discover an algorithm that can perform the arithmetic operation, thereby accomplishing the second objective. 