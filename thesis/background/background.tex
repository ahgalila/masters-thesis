\chapter{Background} \label{sec:background}

The previous chapter discusses how machine learning algorithms are used to allow computer systems to solve problems that would otherwise be impossible to achieve with traditional programming languages. Artificial neural networks, which are inspired by the neural networks found in living organisms, provide a mechanism to represent solutions to such problems. In this chapter, we take a deeper look at how artificial neural networks are constructed and trained as well as the difficulties and challenges they present.

We begin by describing the artificial neuron (Section \ref{sec:background-artificial-neural-networks-perceptron}), which is the basic building block of artificial neural networks, followed by a description of the gradient descent algorithm, which is used to train these neurons. Then in Section \ref{sec:background-artificial-neural-networks-feed-forward-neural-networks} we explain how we can build more complex models by combining many neurons. In Section \ref{sec:background-deep-learning} we discuss the advantages of deep learning, which involves combining several layers of neurons. Section \ref{sec:background-problem-local-minima} explains the problem of local minima which forms a major challenge to effectively train deep neural networks and which comprises the core of the problem we are solving in this thesis. Finally, in Section \ref{sec:background-sequence-modeling}, we explain recurrent neural networks which are a specialized form of neural networks that allow for modeling of sequential data and which are heavily utilized in the experiments presented in Chapter 4.

\input{background/artificial-neural-networks/artificial-neural-networks}

\input{background/sequential-models/sequential-models}

\input{background/the-problem-of-local-minima/the-problem-of-local-minima}

\input{background/summary/summary}