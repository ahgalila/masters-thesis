\section{Summary} \label{sec:theory-summary}

This chapter presented our basic hypothesis. The theory states that individual human learners struggle to learn new concepts through experimentation alone when the number of examples provided to them is limited. However, through interaction with other learners, common symbols for noisy concepts are shared that allows the learner to overcome the challenges in developing accurate models. We hypothesize that the introduction of such a symbolic channel to an artificial neural network model can also help the model achieve higher levels of accuracy when training with an impoverished dataset.

We also proposed a problem domain to validate this hypothesis, namely to teach artificial neural network models to perform arithmetic on images of handwritten digits. We first explained that the process of learning arithmetic operations can be modeled using sequential neural network architectures. We then presented two methods of supplying symbolic information to these models. Next, two theories were discussed on the role the symbols play in guiding the learning system towards discovering an optimum solution to the problem. Finally, we introduced a new form of symbolic representation, that of temperature encoding, that we believe will capture all aspects of learning to perform arithmetic and will therefore produce the best results. 