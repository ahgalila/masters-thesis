\subsection{Challenges in Training Neural Networks} \label{sec:introduction-introduction-machine-learning-challenges-training-neural-networks}

There are two factors that affect the effectiveness (accuracy) of a trained model, namely the variance exhibited in the training examples and the bias assumed in the model. Variance refers to how much the model errs because of changes in the training data, whereas the bias of a model refers to how much the model errs because of incorrect assumptions made by the learning algorithm approximating $\hat{f}$ when compared to the real function $f$. An ideal model will exhibit both low variance and low bias\cite{James:2014:ISL:2517747}.

The variance factor tells us that the size and quality of our training dataset has a huge impact on the quality of the models being developed. The larger the training set and greater the algorithm's representation power, the more accurate our models will be\cite{James:2014:ISL:2517747}. The next section introduces a theory, that including symbols of noisy concepts helps overcome the challenges of training neural networks from small impoverished datasets. Symbols provide concise and accurate information to the learning algorithm that can assist in forming more accurate models.