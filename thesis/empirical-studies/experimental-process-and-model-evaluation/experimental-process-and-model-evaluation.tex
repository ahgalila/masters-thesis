\section{Experimental Process and Model Evaluation} \label{sec:empirical-studies-model-evaluation}

This chapter presents seven experiments that investigate the main hypothesis and objectives set out in Chapter 3. The experiments involve training recurrent neural network models, specifically those based on LSTM units to compare the effectiveness of two or more methods of training these networks. The methods are usually variations of training the models in the presence or absence of symbolic features. After the models are trained, they are then tested on independent test datasets to determine each model's accuracy. The accuracy is the percentage of the number of operations a trained neural network is able to successfully complete relative to the entire dataset. Models are compared based on their accuracies and the ones with the highest score are considered most successful at accomplishing their task.

The process of developing the models involves iteratively training the neural networks on a training set. Each iteration is called an epoch and after every epoch a validation dataset is applied to the neural network using the set of weights obtained so far in the training process. An optimum set of weights is always maintained and is replaced with the current set if the current set outperforms the older set on the validation data. Validation is used to prevent overfitting and to also determine when to stop training. The model is trained for a large predetermined number of epochs. However, a stopping condition is applied where, if the network fails to find a better set of weights than the current optimum after a set number of iterations, training is terminated and the current optimum weights are returned as the final trained model. Section \ref{sec:background-artificial-neural-networks} provides more details on training artificial neural networks.

Most experiments gather and present the following four metrics for each neural network model developed:
\begin{itemize}
	\item Mean Accuracy: After each model is fully trained the test set is applied to obtain the model accuracy. The training and testing of each model is repeated five times with a different distribution of training, validation and test data based on k-fold cross-validation where k is set to 5. The mean accuracy is then calculated and this becomes the accuracy score of the model.
	\item Standard Deviation: The standard deviation of the accuracies obtained from each training attempt is calculated. Standard deviation is used to verify the quality of the results by providing a measure of a model's variance. Too much variance can lower the confidence in the results. Standard deviation is used to calculate the remaining two metrics.
	\item Hypothesis Test: The p-value from a standard hypothesis t-test is used to determine the statistical significance of the results. Typically values less than 0.05 means that the null hypothesis is invalid and therefore the results support the theory being tested.
	\item 95\% Confidence Interval: The confidence interval is the statistical margin of error that is considered when comparing two or more results.
	We usually display the mean accuracy, standard deviation and p-value in tables and show the mean accuracy along with the 95\% confidence interval on graphs.
\end{itemize}